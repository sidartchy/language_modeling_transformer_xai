{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272ac6e3",
   "metadata": {},
   "source": [
    "## Here I'll be trying to create a Dataset and Dataloader class : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b15f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cfa15",
   "metadata": {},
   "source": [
    "Lets load the token ids :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c9443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the bin we created before ( the token_ids list)\n",
    "token_id_bin_path = \"../../data/processed/Initial/initial_token_ids.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1dfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 104, 3077, 4615, 2115,  209], dtype=uint16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = np.fromfile(token_id_bin_path, dtype=np.uint16)\n",
    "\n",
    "token_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f041df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the context-length\n",
    "block_size = 64    # The context length of 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed605a6",
   "metadata": {},
   "source": [
    "Lets create a Dataset class, which returns us the token of size *context_length*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a221dc",
   "metadata": {},
   "source": [
    "### Dataset Explanation\n",
    "\n",
    "In the custom dataset class, the `__len__(self)` function should return the number of **valid training samples**.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Suppose:\n",
    "\n",
    "```python\n",
    "tokens = [10, 11, 12, 13, 14, 15, 16]\n",
    "block_size = 4\n",
    "```\n",
    "\n",
    "Then the valid **input sequences (`X`)** of length `block_size` are:\n",
    "\n",
    "- `[10, 11, 12, 13]`\n",
    "- `[11, 12, 13, 14]`\n",
    "- `[12, 13, 14, 15]`\n",
    "\n",
    "You **cannot go beyond index 2**, because at `idx = 3`:\n",
    "\n",
    "```python\n",
    "X = [13, 14, 15, 16]\n",
    "```\n",
    "\n",
    "To predict the next token (`Y`), you'd need one more token after `16` — but it doesn't exist.\n",
    "\n",
    "#### Therefore:\n",
    "The number of valid training samples is:\n",
    "\n",
    "```\n",
    "len = len(tokens) - block_size = 7 - 4 = 3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf9c0d",
   "metadata": {},
   "source": [
    "### Explanation of `__getitem__(self, idx)`\n",
    "\n",
    "This method is used to retrieve a **single training sample** from the dataset.\n",
    "#### What it does:\n",
    "\n",
    "- It slices `self.data` to generate a training pair:\n",
    "  - `x` is a sequence of `block_size` tokens starting at index `idx`.\n",
    "  - `y` is the next sequence of `block_size` tokens, shifted by 1 — representing the expected next-token predictions for each element in `x`.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Suppose:\n",
    "\n",
    "```python\n",
    "self.data = [10, 11, 12, 13, 14, 15, 16]\n",
    "block_size = 4\n",
    "idx = 0\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "- `x = [10, 11, 12, 13]`\n",
    "- `y = [11, 12, 13, 14]`\n",
    "\n",
    "So the model learns to predict `y[i]` given `x[i]` — that is, to predict the **next token** at every step in the input sequence.\n",
    "\n",
    "This is how autoregressive training works in language models.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff743e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, token_ids, block_size ):\n",
    "        self.block_size = block_size   \n",
    "        self.data = np.array(token_ids, dtype=np.uint16)  # our data is going to be an np array ( for easy slicing )\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.data).shape[0] - self.block_size   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.data[idx:idx+self.block_size], dtype=torch.long)\n",
    "        y = torch.tensor(self.data[idx+1 : idx+self.block_size + 1], dtype = torch.long)\n",
    "\n",
    "        return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b04cd0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47108, 11778)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets just quickly split the dataset  -- first 80% be train data\n",
    "split_idx = int(0.8 * len(token_ids))\n",
    "train_token_ids = token_ids[:split_idx]\n",
    "val_token_ids = token_ids[split_idx:]\n",
    "\n",
    "len(train_token_ids), len(test_token_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25e6333",
   "metadata": {},
   "source": [
    "47108 training tokens, 11778 Validation token Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a37e3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dataset = TokenDataset(train_token_ids, block_size)\n",
    "trainloader = DataLoader(token_dataset, batch_size = 32, shuffle=True, drop_last = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83de75aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 104, 3077, 4615, 2115,  209,   12, 6642,   27, 7661,   58, 4661, 7883,\n",
       "           73, 1148,   72,    5, 1433, 7880, 2732,  248,  819, 2649,   72,    5,\n",
       "         2726, 7870, 7496,   27,    5, 3310,   58, 1996, 7883, 4751,   24,   34,\n",
       "          947, 3290, 4079, 3219, 4751,   16, 7873, 4137, 1148,  148, 4234, 4582,\n",
       "         7870,  185, 2058, 2115,   73, 7317,  270,  911, 4834,  148, 7621,   90,\n",
       "          134, 1387, 6951,   27]),\n",
       " tensor([3077, 4615, 2115,  209,   12, 6642,   27, 7661,   58, 4661, 7883,   73,\n",
       "         1148,   72,    5, 1433, 7880, 2732,  248,  819, 2649,   72,    5, 2726,\n",
       "         7870, 7496,   27,    5, 3310,   58, 1996, 7883, 4751,   24,   34,  947,\n",
       "         3290, 4079, 3219, 4751,   16, 7873, 4137, 1148,  148, 4234, 4582, 7870,\n",
       "          185, 2058, 2115,   73, 7317,  270,  911, 4834,  148, 7621,   90,  134,\n",
       "         1387, 6951,   27, 2147]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the first dataset\n",
    "token_dataset[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e45a3e",
   "metadata": {},
   "source": [
    "Looking Good!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33457e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x): torch.Size([32, 64])\n",
      "Target (y): torch.Size([32, 64])\n",
      "First sample:\n",
      "x: tensor([1084, 1502,  843, 2888,   34,  742, 7140, 7870,  223,  167])\n",
      "y: tensor([1502,  843, 2888,   34,  742, 7140, 7870,  223,  167,   23])\n"
     ]
    }
   ],
   "source": [
    "for batch_features, batch_labels in trainloader:\n",
    "    print(\"Input (x):\", batch_features.shape)   # (batch_size, block_size)\n",
    "    print(\"Target (y):\", batch_labels.shape)  # (batch_size, block_size)\n",
    "    print(\"First sample:\")\n",
    "    print(\"x:\", batch_features[0][:10])\n",
    "    print(\"y:\", batch_labels[0][:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe95ad",
   "metadata": {},
   "source": [
    "the batches are currently ( batch_size, block_size ) shaped. \n",
    "Meaning 32 rows ( samples) of length 64 are being processed at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba889e",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
