{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10302971",
   "metadata": {},
   "source": [
    "### Single Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762eec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00462e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed826e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21da279a530>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2106a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the transformer model\n",
    "\n",
    "n_embed = 120\n",
    "n_layers = 8\n",
    "n_heads = 8\n",
    "head_size = n_embed // n_heads\n",
    "batch_size = 16  # Batch size for training\n",
    "block_size = 256  # Context size for the model\n",
    "dropout = 0.2  # Dropout rate for regularization\n",
    "vocab_size = 8000\n",
    "\n",
    "learning_rate = 3e-4 \n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e23a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Data ( Copied from 2. Data Preparation )\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "token_id_bin_path = \"../../data/processed/Initial/initial_token_ids.bin\"\n",
    "token_ids = np.fromfile(token_id_bin_path, dtype=np.uint16)\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, token_ids, block_size ):\n",
    "        self.block_size = block_size   \n",
    "        self.data = np.array(token_ids, dtype=np.uint16)  # our data is going to be an np array ( for easy slicing )\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.data).shape[0] - self.block_size   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.data[idx:idx+self.block_size], dtype=torch.long)\n",
    "        y = torch.tensor(self.data[idx+1 : idx+self.block_size + 1], dtype = torch.long)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "## Lets just quickly split the dataset  -- first 80% be train data\n",
    "split_idx = int(0.8 * len(token_ids))\n",
    "train_token_ids = token_ids[:split_idx]\n",
    "val_token_ids = token_ids[split_idx:]\n",
    "\n",
    "len(train_token_ids), len(val_token_ids)\n",
    "token_dataset = TokenDataset(train_token_ids, block_size)\n",
    "trainloader = DataLoader(token_dataset, batch_size = 32, shuffle=True, drop_last = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edbc8b5",
   "metadata": {},
   "source": [
    "We know that for each token it consist a embedding vector of dimension n_embed.\n",
    "\n",
    "i.e.. Ei vector of size n_embed*1                ,where i runs to block_size\n",
    "\n",
    "And for each head there is a query matrix and key matrix of size head_size*n_embed. \n",
    "Which is applied to same x for self-head attention\n",
    "\n",
    "and Qi = Wq * Ei = head_size*1 for each block_size and batch_size\n",
    "\n",
    "It can be represented as Linear(n_embed,head_size)\n",
    "\n",
    "How much each query vector attends to key vector is represented from dot product of Ki.Qi at each cell of matrix of size TxT\n",
    "\n",
    "this is represented by \n",
    "Attend = query @ key\n",
    "\n",
    "and the x is represented with the down projection to the dimension of head_size which is concatenated later\n",
    "Vi = Wv * Ei\n",
    "\n",
    "output from single head = attend @ Vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1dfccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embed, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_embed = n_embed\n",
    "        self.head_size = head_size\n",
    "        self.key = nn.Linear(n_embed, head_size)\n",
    "        self.query = nn.Linear(n_embed, head_size)\n",
    "        self.value = nn.Linear(n_embed, head_size)\n",
    "        self.register_buffer('trill', torch.tril(torch.ones(block_size, block_size)))  # Lower triangular matrix for masking\n",
    " \n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape  # B is Batch_size, T is Block_size, C is n_embed\n",
    "        # x is a shape of Batch_size x Block_size x n_embed\n",
    "        key= self.key(x)        # B,T,H = head_size\n",
    "        query = self.query(x)   # B,T,H = head_size\n",
    "\n",
    "        # B,T,H @ B,H,T\n",
    "        attend = query @ key.transpose(-2, -1)  # B,T,T\n",
    "\n",
    "        attend = attend / (self.head_size ** 0.5)  #  Scaled Dot-Product Attention Attention(Q,K,V)=softmax(QK^T/sqrt(d_k))V\n",
    "\n",
    "        # trill = torch.tril(torch.ones(attend.shape[-1], attend.shape[-1]))  # Lower triangular matrix of block_size\n",
    "\n",
    "        attend = attend.masked_fill(self.trill[:T, :T] == 0, float('-inf'))  # Masking future tokens\n",
    "\n",
    "        attend = torch.softmax(attend, dim=-1) # Column-wise softmax IG\n",
    "\n",
    "        value = self.value(x) # B,T,H  \n",
    "\n",
    "        out = attend @ value  # B,T,H\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b9ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,n_embed, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_embed = n_embed\n",
    "        self.n_heads = n_heads\n",
    "        self.head_size = n_embed // n_heads\n",
    "\n",
    "        self.heads = nn.ModuleList([SingleHeadAttention(n_embed, self.head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)  # Concatenate outputs from all heads\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f2de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feed_forward(nn.Module):\n",
    "\n",
    "    # Multi-layer perceptron (MLP) for feed-forward network in transformer\n",
    "    \n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "        nn.Linear(n_embed, 4 * n_embed),  # Up-projection min of 4* n_embed from the paper Attention Is All You Need\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4 * n_embed, n_embed),  # Down-projection back to n_embed\n",
    "        nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.network(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "606d06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Bloack of the Transformer\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embed, n_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(n_embed, n_heads)\n",
    "        self.feed_forward = feed_forward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Creating a residual connection around the attention layer\n",
    "\n",
    "        x = x + self.attention(self.ln1(x))  # Layer normalization before attention\n",
    "        x = x + self.feed_forward(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471194a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)  # Token embeddings\n",
    "        self.position_embedding = nn.Embedding(block_size, n_embed)\n",
    " \n",
    "        self.block = nn.ModuleList([Block(n_embed, n_heads) for _ in range(n_layers)])\n",
    "        self.block = nn.Sequential(*self.block) # Sequentially stacking the blocks\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(n_embed)  # Final layer normalization\n",
    "\n",
    "        self.linear = nn.Linear(n_embed, vocab_size)  # Output layer for vocabulary size\n",
    "\n",
    "    def forward(self, x,target=None):\n",
    "        x = x.long() ## Ensuring the x is of type long for embedding lookup    \n",
    "        B, T = x.size()\n",
    "        positions = torch.arange(0, T, device=x.device)\n",
    "        # Get embeddings\n",
    "        token_emb = self.token_embedding(x)  # (B, T, n_embed)\n",
    "        pos_emb = self.position_embedding(positions)  # (T, n_embed)\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.block(x)\n",
    "\n",
    "        x = self.layer_norm(x)  # Final layer normalization\n",
    "        logits =self.linear(x)  # Output layer to get logits for vocabulary size. B,T,V\n",
    "        if target is not None:\n",
    "            # Reshape for loss calculation\n",
    "            logits_flat = logits.view(-1, logits.size(-1))  # Reshape logits to (B*T, V)\n",
    "            target_flat = target.view(-1)  # Reshape target to (B*T)\n",
    "            loss = nn.CrossEntropyLoss()(logits_flat, target_flat)\n",
    "            return logits, loss  # Return logits, not softmax probabilities\n",
    "        else: \n",
    "            return logits, None  # Return logits, not softmax probabilities\n",
    "    \n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx = Batch_size x Block_size ... B,T\n",
    "        self.eval()  # Set to evaluation mode\n",
    "        with torch.no_grad():  # No need to compute gradients during generation\n",
    "            for _ in range(max_new_tokens):\n",
    "                # Crop idx to the last block_size tokens if it gets too long\n",
    "                # This is the correct line to ensure 'idx_cond' always has a length up to 'block_size'\n",
    "                idx_to_process = idx if idx.size(1) <= self.block_size else idx[:, -self.block_size:]\n",
    "                \n",
    "                # Get predictions\n",
    "                logits, _ = self(idx_to_process)  # Pass the correctly shaped 'idx_to_process' to the forward pass\n",
    "                \n",
    "                # Focus only on the last time step\n",
    "                logits = logits[:, -1, :]  # becomes (B, vocab_size)\n",
    "                \n",
    "                # Apply softmax to get probabilities\n",
    "                probs = torch.softmax(logits, dim=-1)  # (B, vocab_size)\n",
    "                \n",
    "                # Sample from the distribution\n",
    "                idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "                \n",
    "                # Append sampled index to the running sequence\n",
    "                idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "                \n",
    "        return idx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cbdf9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (token_embedding): Embedding(8000, 120)\n",
       "  (position_embedding): Embedding(256, 120)\n",
       "  (block): Sequential(\n",
       "    (0): Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x SingleHeadAttention(\n",
       "            (key): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (query): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (value): Linear(in_features=120, out_features=15, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feed_forward): feed_forward(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=480, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x SingleHeadAttention(\n",
       "            (key): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (query): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (value): Linear(in_features=120, out_features=15, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feed_forward): feed_forward(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=480, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x SingleHeadAttention(\n",
       "            (key): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (query): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (value): Linear(in_features=120, out_features=15, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feed_forward): feed_forward(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=480, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x SingleHeadAttention(\n",
       "            (key): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (query): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (value): Linear(in_features=120, out_features=15, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feed_forward): feed_forward(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=480, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x SingleHeadAttention(\n",
       "            (key): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (query): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (value): Linear(in_features=120, out_features=15, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feed_forward): feed_forward(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=480, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x SingleHeadAttention(\n",
       "            (key): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (query): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (value): Linear(in_features=120, out_features=15, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feed_forward): feed_forward(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=480, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x SingleHeadAttention(\n",
       "            (key): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (query): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (value): Linear(in_features=120, out_features=15, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feed_forward): feed_forward(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=480, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x SingleHeadAttention(\n",
       "            (key): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (query): Linear(in_features=120, out_features=15, bias=True)\n",
       "            (value): Linear(in_features=120, out_features=15, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feed_forward): feed_forward(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=480, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear): Linear(in_features=120, out_features=8000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer()\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74714815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "Transformer                                             --\n",
       "├─Embedding: 1-1                                        960,000\n",
       "├─Embedding: 1-2                                        30,720\n",
       "├─Sequential: 1-3                                       --\n",
       "│    └─Block: 2-1                                       --\n",
       "│    │    └─MultiHeadAttention: 3-1                     58,080\n",
       "│    │    └─feed_forward: 3-2                           115,800\n",
       "│    │    └─LayerNorm: 3-3                              240\n",
       "│    │    └─LayerNorm: 3-4                              240\n",
       "│    └─Block: 2-2                                       --\n",
       "│    │    └─MultiHeadAttention: 3-5                     58,080\n",
       "│    │    └─feed_forward: 3-6                           115,800\n",
       "│    │    └─LayerNorm: 3-7                              240\n",
       "│    │    └─LayerNorm: 3-8                              240\n",
       "│    └─Block: 2-3                                       --\n",
       "│    │    └─MultiHeadAttention: 3-9                     58,080\n",
       "│    │    └─feed_forward: 3-10                          115,800\n",
       "│    │    └─LayerNorm: 3-11                             240\n",
       "│    │    └─LayerNorm: 3-12                             240\n",
       "│    └─Block: 2-4                                       --\n",
       "│    │    └─MultiHeadAttention: 3-13                    58,080\n",
       "│    │    └─feed_forward: 3-14                          115,800\n",
       "│    │    └─LayerNorm: 3-15                             240\n",
       "│    │    └─LayerNorm: 3-16                             240\n",
       "│    └─Block: 2-5                                       --\n",
       "│    │    └─MultiHeadAttention: 3-17                    58,080\n",
       "│    │    └─feed_forward: 3-18                          115,800\n",
       "│    │    └─LayerNorm: 3-19                             240\n",
       "│    │    └─LayerNorm: 3-20                             240\n",
       "│    └─Block: 2-6                                       --\n",
       "│    │    └─MultiHeadAttention: 3-21                    58,080\n",
       "│    │    └─feed_forward: 3-22                          115,800\n",
       "│    │    └─LayerNorm: 3-23                             240\n",
       "│    │    └─LayerNorm: 3-24                             240\n",
       "│    └─Block: 2-7                                       --\n",
       "│    │    └─MultiHeadAttention: 3-25                    58,080\n",
       "│    │    └─feed_forward: 3-26                          115,800\n",
       "│    │    └─LayerNorm: 3-27                             240\n",
       "│    │    └─LayerNorm: 3-28                             240\n",
       "│    └─Block: 2-8                                       --\n",
       "│    │    └─MultiHeadAttention: 3-29                    58,080\n",
       "│    │    └─feed_forward: 3-30                          115,800\n",
       "│    │    └─LayerNorm: 3-31                             240\n",
       "│    │    └─LayerNorm: 3-32                             240\n",
       "├─LayerNorm: 1-4                                        240\n",
       "├─Linear: 1-5                                           968,000\n",
       "================================================================================\n",
       "Total params: 3,353,840\n",
       "Trainable params: 3,353,840\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abb6f7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaf9f6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [1/1464], Loss: 0.0391\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m logits, loss = model(X, y) \u001b[38;5;66;03m# Forward pass \u001b[39;00m\n\u001b[32m     22\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     25\u001b[39m optimizer.step()\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_idx % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\personalProjects\\language_modeling_transformer_xai\\venv\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\personalProjects\\language_modeling_transformer_xai\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\personalProjects\\language_modeling_transformer_xai\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    # if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "    #     losses = estimate_loss()\n",
    "    #     print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # # sample a batch of data\n",
    "    # xb, yb = get_batch('train')\n",
    "\n",
    "    # # evaluate the loss\n",
    "    # logits, loss = model(xb, yb)\n",
    "    # optimizer.zero_grad(set_to_none=True)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "for epoch in range(1):\n",
    "    for batch_idx, (X, y) in enumerate(trainloader):\n",
    "        X, y = X.to(device, dtype=torch.long), y.to(device, dtype=torch.long)\n",
    "        logits, loss = model(X, y) # Forward pass \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(trainloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ee9ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../models/initial_model_10E.pth\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374e41d",
   "metadata": {},
   "source": [
    "##### Loading the model and teting the generation code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00ec0e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model \n",
    "model.eval()\n",
    "model_path = \"../../models/initial_model_10E.pth\"\n",
    "state_dict = torch.load(model_path, weights_only=True)\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17051e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m device = \u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m \n\u001b[32m      2\u001b[39m  \u001b[38;5;66;03m## Generation using the 'generate function' \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mTransformer.generate\u001b[39m\u001b[34m(self, idx, max_new_tokens)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens):\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# idx is of shape (Batch_size, Block_size)  \u001b[39;00m\n\u001b[32m     48\u001b[39m     idx = idx[:,-block_size] \u001b[38;5;66;03m#Keep only last block_size tokens\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     logits, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get logits for the current input\u001b[39;00m\n\u001b[32m     52\u001b[39m     logits = logits[:,-\u001b[32m1\u001b[39m,:] \u001b[38;5;66;03m# Get logit for the last token in the sequence of each Batch with shape `(Batch_size, Vocab_size)`\u001b[39;00m\n\u001b[32m     54\u001b[39m     probs = torch.softmax(logits, dim=-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Apply softmax to get probabilities in the vocabulary dimension\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\personalProjects\\language_modeling_transformer_xai\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\personalProjects\\language_modeling_transformer_xai\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, target)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x,target=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     18\u001b[39m     x = x.long() \u001b[38;5;66;03m## Ensuring the x is of type long for embedding lookup    \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     positions = torch.arange(\u001b[32m0\u001b[39m, \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, device=x.device, dtype=torch.long)\n\u001b[32m     22\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.token_embedding(x) + \u001b[38;5;28mself\u001b[39m.position_embedding(positions)\n\u001b[32m     25\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.block(x)  \u001b[38;5;66;03m# Passing through the transformer blocks\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    " ## Generation using the 'generate function' \n",
    "model.generate(idx=torch.zeros(1, block_size, dtype=torch.long).to(device), max_new_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd452e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
